{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+yg2dRR85vSPaM8WvfJL5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKSHIT3107/assignment1/blob/main/assgn3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdK82lNoDbwr",
        "outputId": "379e951d-6b9b-443c-a9e6-8136a0dafabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial R^2 score: 0.7926620169101526\n",
            "PCA R^2 score: 0.7926620169101533\n",
            "PCA improved the model performance.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/USA_Housing (2).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "data.head()\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Split dataset into input features (X) and target variable (y)\n",
        "X = data.drop(columns=['Price'])\n",
        "y = data['Price']\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Initialize KFold for 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "# Arrays to store results for each fold\n",
        "betas = []\n",
        "r2_scores = []\n",
        "predicted_values = []\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit linear regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate R2 score\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Store beta coefficients, predicted values, and R2 score\n",
        "    betas.append(model.coef_)\n",
        "    r2_scores.append(r2)\n",
        "    predicted_values.append(y_pred)\n",
        "\n",
        "# Identify the best beta (β) matrix with the maximum R2 score\n",
        "best_beta_index = np.argmax(r2_scores)\n",
        "best_beta = betas[best_beta_index]\n",
        "\n",
        "{\n",
        "    \"best_beta\": best_beta,\n",
        "    \"max_r2_score\": r2_scores[best_beta_index]\n",
        "}\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into 70% training and 30% testing based on the best beta\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Train the model with the best beta on the training data\n",
        "final_model = LinearRegression()\n",
        "final_model.coef_ = best_beta\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_final = final_model.predict(X_test)\n",
        "\n",
        "# Calculate R2 score for the final model\n",
        "final_r2_score = r2_score(y_test, y_pred_final)\n",
        "\n",
        "final_r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Split the dataset into training (56%), validation (14%), and test (30%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.44, random_state=1)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.682, random_state=1) # 0.682 * 0.44 ≈ 30%\n",
        "\n",
        "# Define gradient descent function for multiple linear regression\n",
        "def gradient_descent(X, y, learning_rate, iterations):\n",
        "    m, n = X.shape\n",
        "    beta = np.zeros(n)\n",
        "    for _ in range(iterations):\n",
        "        y_pred = X.dot(beta)\n",
        "        gradients = -2 / m * X.T.dot(y - y_pred)\n",
        "        beta -= learning_rate * gradients\n",
        "    return beta\n",
        "\n",
        "# Set learning rates and number of iterations\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "iterations = 1000\n",
        "\n",
        "# Store results\n",
        "beta_values = []\n",
        "val_r2_scores = []\n",
        "test_r2_scores = []\n",
        "\n",
        "# Train and evaluate models with different learning rates\n",
        "for lr in learning_rates:\n",
        "    # Compute beta using gradient descent\n",
        "    beta = gradient_descent(X_train, y_train.values, learning_rate=lr, iterations=iterations)\n",
        "    beta_values.append(beta)\n",
        "\n",
        "    # Predict on validation and test sets\n",
        "    y_val_pred = X_val.dot(beta)\n",
        "    y_test_pred = X_test.dot(beta)\n",
        "\n",
        "    # Compute R2 scores\n",
        "    val_r2 = r2_score(y_val, y_val_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    val_r2_scores.append(val_r2)\n",
        "    test_r2_scores.append(test_r2)\n",
        "\n",
        "# Find the best set of coefficients based on the highest validation R2 score\n",
        "best_index = np.argmax(val_r2_scores)\n",
        "best_beta = beta_values[best_index]\n",
        "\n",
        "{\n",
        "    \"best_beta\": best_beta,\n",
        "    \"best_learning_rate\": learning_rates[best_index],\n",
        "    \"max_val_r2_score\": val_r2_scores[best_index],\n",
        "    \"corresponding_test_r2_score\": test_r2_scores[best_index]\n",
        "}\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define column names\n",
        "column_names = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "                \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\",\n",
        "                \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\",\n",
        "                \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\",\n",
        "                \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
        "data = pd.read_csv(url, names=column_names, na_values=\"?\")\n",
        "# Replace NaN values with the mean or median of each column\n",
        "data.fillna(data.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# Drop rows where 'price' is NaN\n",
        "data.dropna(subset=['price'], inplace=True)\n",
        "data['price'] = pd.to_numeric(data['price'])\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert \"num_doors\" and \"num_cylinders\" to numeric\n",
        "data['num_doors'] = data['num_doors'].map({'two': 2, 'four': 4}).astype(float)\n",
        "data['num_cylinders'] = data['num_cylinders'].map({\n",
        "    'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'eight': 8, 'twelve': 12\n",
        "}).astype(float)\n",
        "\n",
        "# Dummy encoding for \"body_style\" and \"drive_wheels\"\n",
        "data = pd.get_dummies(data, columns=['body_style', 'drive_wheels'])\n",
        "\n",
        "# Label encoding for \"make\", \"aspiration\", \"engine_location\", \"fuel_type\"\n",
        "label_cols = [\"make\", \"aspiration\", \"engine_location\", \"fuel_type\"]\n",
        "for col in label_cols:\n",
        "    data[col] = LabelEncoder().fit_transform(data[col])\n",
        "\n",
        "# Binary encoding for \"fuel_system\" (1 for 'pfi', 0 otherwise)\n",
        "data['fuel_system'] = np.where(data['fuel_system'].str.contains('pfi'), 1, 0)\n",
        "\n",
        "# Binary encoding for \"engine_type\" (1 for 'ohc', 0 otherwise)\n",
        "data['engine_type'] = np.where(data['engine_type'].str.contains('ohc'), 1, 0)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Separate input features and target variable\n",
        "X = data.drop(columns=['price'])\n",
        "y = data['price']\n",
        "\n",
        "# Scale input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step to ensure no NaN values are present before model training\n",
        "# Replace remaining NaN values with the mean for numeric columns\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into 70% training and 30% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Train and evaluate the model\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Calculate R^2 score\n",
        "initial_r2_score = r2_score(y_test, y_pred)\n",
        "print(f\"Initial R^2 score: {initial_r2_score}\")\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Apply PCA to reduce dimensionality\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Split PCA-transformed data into training and testing sets\n",
        "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Train and evaluate the model on PCA-transformed data\n",
        "regressor_pca = LinearRegression()\n",
        "regressor_pca.fit(X_train_pca, y_train)\n",
        "y_pred_pca = regressor_pca.predict(X_test_pca)\n",
        "\n",
        "# Calculate R^2 score on PCA-transformed data\n",
        "pca_r2_score = r2_score(y_test, y_pred_pca)\n",
        "print(f\"PCA R^2 score: {pca_r2_score}\")\n",
        "\n",
        "# Compare results\n",
        "if pca_r2_score > initial_r2_score:\n",
        "    print(\"PCA improved the model performance.\")\n",
        "else:\n",
        "    print(\"PCA did not improve the model performance.\")\n"
      ]
    }
  ]
}